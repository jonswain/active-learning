{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning\n",
    "\n",
    "Active learning is used when we have some sort of scoring function that is too computationally expensive to label the full library of compounds. A machine learning model is trained on a subset of the data and used to score all compounds from within the library. The compounds with the best scores from the ML are labelled using the more expensive function, and the data from this pooled and used to train a new machine learning model. This cycle is repeated until a finish criteria is met. \n",
    "\n",
    "Currently this example trains a model to find the compound in the library with the lowerest docking score.\n",
    "\n",
    "The initial steps in this notebook are:\n",
    "1. A random sample of the unlabelled data is selected and labelled using the expensive scoring function\n",
    "2. These labelled datapoints are used to train a simple machine learning (random forest) regressor\n",
    "\n",
    "Followed the a repeating cycle:\n",
    "\n",
    "3. The regressor is used to score the entire library\n",
    "4. The compounds with the highest scores from the machine learning regressor are labelled using the expensive scoring function\n",
    "5. The labels from the expensive scoring function are pooled and the machine learning model is re-trained\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, PandasTools\n",
    "from rdkit import RDLogger\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s] %(levelname)s: %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dock_mol(mol):\n",
    "    with Chem.SDWriter(\"data/docking/tmp_conf.sdf\") as w:\n",
    "        m = Chem.AddHs(mol)\n",
    "        cids = AllChem.EmbedMultipleConfs(m, numConfs=5, numThreads=0)\n",
    "        confs = m.GetConformers()\n",
    "        for c in confs:\n",
    "            w.write(m, confId=c.GetId())\n",
    "\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"./smina.osx.12\",\n",
    "            \"--exhaustiveness\",\n",
    "            \"10\",\n",
    "            \"--cpu\",\n",
    "            \"10\",\n",
    "            \"--seed\",\n",
    "            \"0\",\n",
    "            \"--autobox_ligand\",\n",
    "            \"data/docking/ligand_only.pdb\",\n",
    "            \"-r\",\n",
    "            \"data/docking/protein_minus_ligand.pdb\",\n",
    "            \"-l\",\n",
    "            \"data/docking/tmp_conf.sdf\",\n",
    "            \"-o\",\n",
    "            \"data/docking/tmp_conf_docked.sdf.gz\",\n",
    "        ],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "    )\n",
    "\n",
    "    with gzip.open(\"data/docking/tmp_conf_docked.sdf.gz\", \"rb\") as f_in:\n",
    "        with open(\"data/docking/tmp_conf_docked.sdf\", \"wb\") as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    # The output sdf wasn't loading so this is a workaround\n",
    "    with open(\"data/docking/tmp_conf_docked.sdf\", \"r\") as f:\n",
    "        text = f.read()\n",
    "    affinities = re.findall(r\"<minimizedAffinity>\\n(-\\d.\\d+)\", text)\n",
    "    affinities = [float(x) for x in affinities]\n",
    "    return min(affinities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_virtual_library() -> pd.DataFrame:\n",
    "    \"\"\"Constructs a virtual library by coupling building blocks from the input smi files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the molecular objects and SMILES strings of the products.\n",
    "    \"\"\"\n",
    "    log.info(\"Building virtual library\")\n",
    "    try:\n",
    "        library = pd.read_csv(\"data/library.csv\", index_col=\"smiles\")\n",
    "        library[\"mol\"] = [Chem.MolFromSmiles(s) for s in tqdm(library.index.to_list())]\n",
    "    except FileNotFoundError:\n",
    "        reaction_smarts = \"N[c:4][c:3]C(O)=O.[#6:1][NH2].[#6:2]C(=O)[OH]>>[C:2]c1n[c:4][c:3]c(=O)n1[C:1]\"\n",
    "        bb_types = [\"aminobenzoic\", \"carboxylic_acids\", \"primary_amines\"]\n",
    "        rxn = AllChem.ReactionFromSmarts(reaction_smarts)\n",
    "\n",
    "        building_blocks = []\n",
    "        for bb in bb_types:\n",
    "            smil = []\n",
    "            with open(Path(f\"data/{bb}_100.smi\"), \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    smiles, _ = line.split()\n",
    "                    smil.append(smiles)\n",
    "            building_blocks.append(smil)\n",
    "\n",
    "        total_prods = math.prod([len(x) for x in building_blocks])\n",
    "\n",
    "        product_list = []\n",
    "        for reagents in tqdm(product(*building_blocks), total=total_prods):\n",
    "            reagent_mol_list = [Chem.MolFromSmiles(x) for x in reagents]\n",
    "            products = rxn.RunReactants(reagent_mol_list)\n",
    "            if products:\n",
    "                Chem.SanitizeMol(products[0][0])\n",
    "                product_list.append(products[0][0])\n",
    "        library = pd.DataFrame(\n",
    "            product_list,\n",
    "            index=[Chem.MolToSmiles(m) for m in product_list],\n",
    "            columns=[\"mol\"],\n",
    "        )\n",
    "        library.index.name = \"smiles\"\n",
    "        library[\"slow_scores\"] = np.NaN\n",
    "        library[\"model_scores\"] = np.NaN\n",
    "        PandasTools.AddMurckoToFrame(library, molCol=\"mol\", MurckoCol=\"scaffold\")\n",
    "        library.to_csv(\"data/library.csv\")\n",
    "    log.info(\"Virtual library built with %s products\", len(library))\n",
    "    return library\n",
    "\n",
    "\n",
    "def slow_function(mols: pd.Series) -> np.array:\n",
    "    \"\"\"The slow scoring function. This function takes too long to score the entire library.\n",
    "\n",
    "    Args:\n",
    "        mols (pd.Series): The input molecules.\n",
    "\n",
    "    Returns:\n",
    "        np.arary: The scores of the molecules.\n",
    "    \"\"\"\n",
    "    log.info(\"Scoring %s compounds with slow scoring function\", len(mols))\n",
    "    return np.array([dock_mol(mol) for mol in tqdm(mols)])\n",
    "\n",
    "\n",
    "def create_morgan_fingerprints(library: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Creates Morgan fingerprints for the input library.\n",
    "\n",
    "    Args:\n",
    "        library (pd.DataFrame): The input library.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The Morgan fingerprints of the input library.\n",
    "    \"\"\"\n",
    "    log.info(\"Creating Morgan fingerprints\")\n",
    "    try:\n",
    "        fps_df = pd.read_csv(\"data/fingerprints.csv\").set_index(\"smiles\")\n",
    "        fps_df.fillna(\"\", inplace=True)\n",
    "    except FileNotFoundError:\n",
    "        fps = [\n",
    "            list(AllChem.GetMorganFingerprintAsBitVect(mol, radius=2))\n",
    "            for mol in tqdm(library.mol)\n",
    "        ]\n",
    "        fps_df = pd.DataFrame(\n",
    "            fps, columns=[f\"fp_{x}\" for x in range(len(fps[0]))], index=library.index\n",
    "        )\n",
    "        fps_df.to_csv(\"data/fingerprints.csv\")\n",
    "    return fps_df\n",
    "\n",
    "\n",
    "def train_ml_model(\n",
    "    library: pd.DataFrame, fingerprints: pd.DataFrame\n",
    ") -> RandomForestRegressor:\n",
    "    \"\"\"Trains a random forest regressor model on slow scores for the input library.\n",
    "\n",
    "    Args:\n",
    "        library (pd.DataFrame): The input library.\n",
    "        fingerprints (pd.DataFrame): The Morgan fingerprints of the input library.\n",
    "\n",
    "    Returns:\n",
    "        RandomForestRegressor: The trained random forest regressor model.\n",
    "    \"\"\"\n",
    "    log.info(\"Training model with slow scores\")\n",
    "    scored = library[~library[\"slow_scores\"].isna()]\n",
    "    X = fingerprints.loc[scored.index]\n",
    "    y = scored[\"slow_scores\"]\n",
    "    regressor = RandomForestRegressor()\n",
    "    regressor.fit(X, y)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def score_compounds(X: pd.DataFrame, regressor: RandomForestRegressor) -> np.array:\n",
    "    \"\"\"Scores the input compounds with the trained models.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): The input compounds.\n",
    "        regressors (list[RandomForestRegressor]): The trained random forest regressor models.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The input compounds with the model scores.\n",
    "    \"\"\"\n",
    "    return regressor.predict(X)\n",
    "\n",
    "\n",
    "def score_library(\n",
    "    library: pd.DataFrame,\n",
    "    regressor: RandomForestRegressor,\n",
    "    fingerprints: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Scores the entire library with the trained model.\n",
    "\n",
    "    Args:\n",
    "        library (pd.DataFrame): The input library.\n",
    "        regressor (RandomForestRegressor): The trained random forest regressor model.\n",
    "        fingerprints (pd.DataFrame): The Morgan fingerprints of the input library.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input library with the model scores.\n",
    "    \"\"\"\n",
    "    log.info(\"Scoring entire library with model\")\n",
    "    library[\"model_scores\"] = score_compounds(fingerprints, regressor)\n",
    "    return library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-15 18:14:24,935] INFO: Building virtual library\n",
      "100%|██████████| 132500/132500 [00:10<00:00, 13066.17it/s]\n",
      "[2024-02-15 18:14:35,441] INFO: Virtual library built with 132500 products\n",
      "[2024-02-15 18:14:35,442] INFO: Creating Morgan fingerprints\n",
      "[2024-02-15 18:14:44,858] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [07:37<00:00, 45.74s/it]\n",
      "[2024-02-15 18:22:22,238] INFO: Active learning round 1\n",
      "[2024-02-15 18:22:22,239] INFO: Training model with slow scores\n",
      "[2024-02-15 18:22:22,350] INFO: Scoring entire library with model\n",
      "[2024-02-15 18:22:23,099] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [10:40<00:00, 64.10s/it]\n",
      "[2024-02-15 18:33:04,055] INFO: Current best score: -9.54\n",
      "[2024-02-15 18:33:04,056] INFO: Active learning round 2\n",
      "[2024-02-15 18:33:04,056] INFO: Training model with slow scores\n",
      "[2024-02-15 18:33:04,132] INFO: Scoring entire library with model\n",
      "[2024-02-15 18:33:04,588] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [09:38<00:00, 57.87s/it]\n",
      "[2024-02-15 18:42:43,314] INFO: Current best score: -9.54\n",
      "[2024-02-15 18:42:43,315] INFO: Active learning round 3\n",
      "[2024-02-15 18:42:43,315] INFO: Training model with slow scores\n",
      "[2024-02-15 18:42:43,393] INFO: Scoring entire library with model\n",
      "[2024-02-15 18:42:43,843] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [08:30<00:00, 51.09s/it]\n",
      "[2024-02-15 18:51:14,700] INFO: Current best score: -9.54\n",
      "[2024-02-15 18:51:14,700] INFO: Active learning round 4\n",
      "[2024-02-15 18:51:14,700] INFO: Training model with slow scores\n",
      "[2024-02-15 18:51:14,790] INFO: Scoring entire library with model\n",
      "[2024-02-15 18:51:15,237] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [07:16<00:00, 43.68s/it]\n",
      "[2024-02-15 18:58:32,010] INFO: Current best score: -9.54\n",
      "[2024-02-15 18:58:32,010] INFO: Active learning round 5\n",
      "[2024-02-15 18:58:32,010] INFO: Training model with slow scores\n",
      "[2024-02-15 18:58:32,138] INFO: Scoring entire library with model\n",
      "[2024-02-15 18:58:32,621] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [07:41<00:00, 46.18s/it]\n",
      "[2024-02-15 19:06:14,406] INFO: Current best score: -9.54\n",
      "[2024-02-15 19:06:14,407] INFO: Active learning round 6\n",
      "[2024-02-15 19:06:14,407] INFO: Training model with slow scores\n",
      "[2024-02-15 19:06:14,542] INFO: Scoring entire library with model\n",
      "[2024-02-15 19:06:15,014] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [07:33<00:00, 45.39s/it]\n",
      "[2024-02-15 19:13:48,960] INFO: Current best score: -9.54\n",
      "[2024-02-15 19:13:48,960] INFO: Active learning round 7\n",
      "[2024-02-15 19:13:48,960] INFO: Training model with slow scores\n",
      "[2024-02-15 19:13:49,112] INFO: Scoring entire library with model\n",
      "[2024-02-15 19:13:49,618] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [07:53<00:00, 47.34s/it]\n",
      "[2024-02-15 19:21:42,998] INFO: Current best score: -9.54\n",
      "[2024-02-15 19:21:42,999] INFO: Active learning round 8\n",
      "[2024-02-15 19:21:42,999] INFO: Training model with slow scores\n",
      "[2024-02-15 19:21:43,172] INFO: Scoring entire library with model\n",
      "[2024-02-15 19:21:43,694] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [13:11<00:00, 79.11s/it]\n",
      "[2024-02-15 19:34:54,787] INFO: Current best score: -9.54\n",
      "[2024-02-15 19:34:54,787] INFO: Active learning round 9\n",
      "[2024-02-15 19:34:54,788] INFO: Training model with slow scores\n",
      "[2024-02-15 19:34:55,123] INFO: Scoring entire library with model\n",
      "[2024-02-15 19:34:56,104] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [10:36<00:00, 63.67s/it]\n",
      "[2024-02-15 19:45:32,845] INFO: Current best score: -9.54\n",
      "[2024-02-15 19:45:32,845] INFO: Active learning round 10\n",
      "[2024-02-15 19:45:32,845] INFO: Training model with slow scores\n",
      "[2024-02-15 19:45:33,011] INFO: Scoring entire library with model\n",
      "[2024-02-15 19:45:33,518] INFO: Scoring 10 compounds with slow scoring function\n",
      "100%|██████████| 10/10 [10:07<00:00, 60.73s/it]\n",
      "[2024-02-15 19:55:40,817] INFO: Current best score: -9.54\n",
      "[2024-02-15 19:55:40,817] INFO: Active learning took 6056.0 seconds\n",
      "[2024-02-15 19:55:40,824] INFO: Scoring 100 compounds with slow scoring function\n",
      " 11%|█         | 11/100 [11:37<1:48:45, 73.32s/it]"
     ]
    }
   ],
   "source": [
    "def run_active_learning(\n",
    "    library: pd.DataFrame,\n",
    "    fingerprints: pd.DataFrame,\n",
    "    compounds_per_round: int,\n",
    "    number_of_rounds: int,\n",
    "    minimize: bool,\n",
    ") -> tuple[float, float, float]:\n",
    "    \"\"\"Runs active learning on the virtual library.\n",
    "\n",
    "    Args:\n",
    "        library (pd.DataFrame): The input virtual library.\n",
    "        fingerprints (pd.DataFrame): The Morgan fingerprints of the input library.\n",
    "        compounds_per_round (int): Number of compounds to select per round.\n",
    "        number_of_rounds (int): Number of active learning rounds.\n",
    "        minimize (bool): Whether to minimize or maximize the slow scoring function.\n",
    "\n",
    "    Returns:\n",
    "        tuple[float, float, float]: The true best score, the active learning best score,\n",
    "        and the random sample best score.\n",
    "    \"\"\"\n",
    "    # Select initial random sample\n",
    "    start = time.time()\n",
    "    initial_sample = library.sample(compounds_per_round)\n",
    "    library[\"slow_scores\"] = np.NaN\n",
    "\n",
    "    # Score the initial sample\n",
    "    initial_scores = slow_function(initial_sample.mol)\n",
    "\n",
    "    # Save the slow scores\n",
    "    library.loc[initial_sample.index, \"slow_scores\"] = initial_scores\n",
    "\n",
    "    # Run active learning\n",
    "    for al_round in range(number_of_rounds):\n",
    "        log.info(\"Active learning round %s\", al_round + 1)\n",
    "\n",
    "        # Train the ML model\n",
    "        model = train_ml_model(library, fingerprints)\n",
    "\n",
    "        # Use the model to score the entire virtual library\n",
    "        library = score_library(library, model, fingerprints)\n",
    "\n",
    "        # Select the top scoring molecules with no slow scores\n",
    "        top_compounds = (\n",
    "            library[library[\"slow_scores\"].isna()]\n",
    "            .sort_values(\"slow_scores\", ascending=minimize)\n",
    "            .head(compounds_per_round)\n",
    "        )\n",
    "\n",
    "        # Score the top molecules with the slow function\n",
    "        slow_scores = slow_function(top_compounds.mol)\n",
    "\n",
    "        # Save the slow scores\n",
    "        library.loc[top_compounds.index, \"slow_scores\"] = slow_scores\n",
    "        if MINIMIZE:\n",
    "            log.info(\"Current best score: %.2f\", library.slow_scores.min())\n",
    "        else:\n",
    "            log.info(\"Current best score: %.2f\", library.slow_scores.max())\n",
    "\n",
    "    end = time.time()\n",
    "    log.info(\"Active learning took %.1f seconds\", end - start)\n",
    "\n",
    "    if MINIMIZE:\n",
    "        return library.slow_scores.min()\n",
    "    else:\n",
    "        return library.slow_scores.max()\n",
    "\n",
    "\n",
    "# Active learning parameters\n",
    "COMPOUNDS_PER_ROUND = 10\n",
    "NUMBER_OF_ROUNDS = 10\n",
    "MINIMIZE = True\n",
    "\n",
    "# Create the virtual library\n",
    "library = build_virtual_library()\n",
    "\n",
    "# Create morgan fingerprints for the library\n",
    "fingerprints = create_morgan_fingerprints(library)\n",
    "\n",
    "al_best = run_active_learning(\n",
    "    library, fingerprints, COMPOUNDS_PER_ROUND, NUMBER_OF_ROUNDS, MINIMIZE\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "random_scores = slow_function(\n",
    "    library.sample(COMPOUNDS_PER_ROUND * NUMBER_OF_ROUNDS).mol\n",
    ")\n",
    "random_best = min(random_scores) if MINIMIZE else max(random_scores)\n",
    "end = time.time()\n",
    "\n",
    "log.info(\n",
    "    \"Scoring entire library with slow scoring function took %.1f seconds\", end - start\n",
    ")\n",
    "\n",
    "percent_scores = COMPOUNDS_PER_ROUND * NUMBER_OF_ROUNDS / len(library) * 100\n",
    "log.info(\n",
    "    f\"When scoring {percent_scores:.2f}% of the library: AL best: {al_best:.2f}, Random sample best: {random_best:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
